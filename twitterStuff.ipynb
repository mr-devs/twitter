{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T20:28:00.843391Z",
     "start_time": "2019-07-28T20:28:00.831424Z"
    }
   },
   "outputs": [],
   "source": [
    "class twitterStuff:\n",
    "    import tweepy\n",
    "    import json\n",
    "    import time\n",
    "    def pullTweets(screenName='dadsaysjokes', tweetCutoff=3200):\n",
    "        ''''\n",
    "        A function to pull tweets objects based on a user's screen name and number of tweets. \n",
    "\n",
    "            INPUTS:\n",
    "            - screenName = the user's screen name(handle) to pull (string)\n",
    "            - tweetCutoff = this is an integer which represents how many tweets will be pulled (default = 3200 tweets)\n",
    "\n",
    "            OUTPUTS:\n",
    "            - screenName_tweets.json (where 'screenName' is the user handle input)\n",
    "\n",
    "        ''' ''\n",
    "        # Authorize with application tokens\n",
    "        auth = tweepy.OAuthHandler(\n",
    "            'nLQR3kn2wZaGnIx96caKCO3v3',\n",
    "            'xkzbUfh43hhjy4QhGlDO1ZgABUUrxZ17fFAnKEvl3n8hNTXjxs')\n",
    "        auth.set_access_token(\n",
    "            '1127969462521618434-6fRp67ll6LZWaFa8bi0zXGpDORHJ5X',\n",
    "            'M1OOzWaegn5Cs5o5wjtsYn2m8LdRL0E08ahlocQLCWjbt')\n",
    "\n",
    "        # initialize tweepy into 'api'\n",
    "        api = tweepy.API(auth)\n",
    "\n",
    "        # iterate through a user's timeline and grab tweets, placing them into all_tweets\n",
    "        all_tweets = []\n",
    "\n",
    "        try:\n",
    "            for tweet in tweepy.Cursor(\n",
    "                    api.user_timeline,\n",
    "                    screen_name=screenName,\n",
    "                    include_entities=True,\n",
    "                    tweet_mode='extended',\n",
    "                    wait_on_rate_limit=True,\n",
    "                    wait_on_rate_limit_notify=True).items(tweetCutoff):\n",
    "                # append each tweet to all_tweets\n",
    "                all_tweets.append(tweet)\n",
    "\n",
    "            # write the json\n",
    "            with open('{}_tweets.json'.format(screenName), 'w', encoding='utf-8') as f:\n",
    "                for tweet in all_tweets:\n",
    "                    f.write(json.dumps(tweet._json) + '\\n')\n",
    "                print('{}_tweets.json was successfully created.'.format(\n",
    "                    screenName))\n",
    "\n",
    "        except tweepy.TweepError as error:\n",
    "            reason = error.reason\n",
    "            response = error.response\n",
    "            apiCode = error.api_code\n",
    "            errorResponse = '''\n",
    "            ********\n",
    "            The following TweepError has been encountered for handle: {}\n",
    "            Reason: {}\n",
    "            Response: {}\n",
    "            API Code: {}\n",
    "            See https://developer.twitter.com/en/docs/basics/response-codes.html for more info.\n",
    "            --->Moving on...\n",
    "            ********\n",
    "            '''.format(screenName, reason, response, apiCode)\n",
    "            print(errorResponse)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the display parameters so that you can properly inspect output below\n",
    "display.max_colwidth = 200\n",
    "display.max_columns = 'None'\n",
    "display.max_info_columns = 200\n",
    "pd.set_option('display.max_rows', 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\mdeve\\\\OneDrive\\\\Documents\\\\Twitter_Tweepy\\\\data\\\\Network_Ideologies_Data\\\\congressData')\n",
    "\n",
    "handlesFile = 'C:\\\\Users\\\\mdeve\\\\OneDrive\\\\Documents\\\\Twitter_Tweepy\\\\data\\\\Network_Ideologies_Data\\\\twitterAllHandles_7.20.19.csv'\n",
    "\n",
    "data = pd.read_csv(handlesFile)\n",
    "\n",
    "for handle in data.Twitter:\n",
    "    try:\n",
    "        twitterStuff.pullTweets(handle)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Check which handles did not create files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of the files in the directory\n",
    "files = os.listdir()\n",
    "\n",
    "# put that list into a dataframe\n",
    "handleFiles = pd.DataFrame(files, columns={'Twitter'})\n",
    "\n",
    "# split on the '_tweets to get just the handles - split into different columns\n",
    "handless = handleFiles['Twitter'].str.split('_tweets', expand=True)\n",
    "\n",
    "# take only the handles column, lowercase them all\n",
    "files_files = handless[0].str.lower()\n",
    "\n",
    "# lowercase all handles in the original list of handles as well\n",
    "data['Twitter'] = data['Twitter'].str.lower()\n",
    "\n",
    "# turn the list of handles from files into a dataframe to allow for use of 'isin()' below\n",
    "files_files = pd.DataFrame(files_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "missingHandles = data['Twitter'][data['Twitter'].isin(files_files[0]) == False]\n",
    "missingHandles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(missingHandles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun the code again, as a double check, on the remaining handles\n",
    "# in 'missingHandles' to ensure all handles are captured. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\mdeve\\\\OneDrive\\\\Documents\\\\Twitter_Tweepy\\\\data\\\\Network_Ideologies_Data\\\\congressData')\n",
    "\n",
    "for handle in missingHandles:\n",
    "    try:\n",
    "        twitterStuff.pullTweets(handle)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save these missing handles to a dataframe\n",
    "missingHandles = pd.DataFrame(missingHandles)\n",
    "missingHandles.to_csv('missingHandles_2.csv')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
